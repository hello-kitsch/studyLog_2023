{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66b4fb36",
   "metadata": {},
   "source": [
    "# 머신러닝이란?\n",
    "- 명시적인 프로그래밍 없이 컴퓨터가 학습하는 능력을 갖추게 하는 연구 분야\n",
    "- 어떤 작업T에 대한 컴퓨터 프로그램의 성능을 P로 측정했을 때 경험E로 인해 성능이 향상됐다면,\n",
    "작업T와 성능 측정P에 대해 경험E로 학습한 것.\n",
    "  - sample: training set, training instance\n",
    "  - 작업T(ex.새로운 메일이 스팸인지 구분), 경험E(training data), 성능 측정P(직접 정의, accracy등)\n",
    "\n",
    "# 머신러닝을 사용하는 이유\n",
    "- 스팸 필터를 만드는 예시에서\n",
    "  - 전통적 프로그래밍 기법 활용\n",
    "    1. 스팸에 어떤 단어들이 나타나는지 살펴보기->패턴을 감지 (오차 분석 & 문제 연구)\n",
    "    2. 발견한 패턴을 감지하는 알고리즘을 직접 작성하여 분류 (규칙 작성)\n",
    "    3. 프로그램 테스트, 런칭까지의 성능이 나올때까지 1,2단계를 반복 (평가)\n",
    "  - 머신러닝 기법 활용: 패턴을 감지하여 좋은 기준을 자동으로 학습 \n",
    "  (2단계에 머신러닝 알고리즘 훈련)\n",
    "  - 머신러닝 기반 자동화: 데이터 업데이트->머신러닝 알고리즘 훈련->솔루션 평가->론칭을 루프로 반복\n",
    "- 너무 복잡하거나 알려진 알고리즘이 없는 문제에서도 머신러닝이 유용함.\n",
    "  - 음성인식: 너무 많은 음소의 조합이라는 경우의 수에 따른 구분이 어려운 경우\n",
    "  - 데이터 마이닝: 머신러닝이 찾아낸 솔루션을 분석하며 문제에 대한 이해 증가, 예상치 못한 연관관계/새로운 추세 발견\n",
    "- 머신러닝이 효과적인 분야\n",
    "  - 기존 솔루션으로는 많은 수동 조정과 규칙이 필요한 문제: 간결한 코드 및 높은 효율의 수행\n",
    "  - 전통적 방식으론 해결방법이 없는 복잡한 문제\n",
    "  - 유동적인 환경\n",
    "  - 복잡한 문제/대량의 데이터에서 통찰 얻기\n",
    "\n",
    "# 애플리케이션 사례\n",
    "- 생산라인, 제품 이미지 분석해 자동 분류: 이미지 분류 작업, CNN 사용\n",
    "- 뇌 스캔 종양 진단: 시맨틱 분할 작업, CNN\n",
    "- 뉴스 기사 분류: NLP(텍스트 분류, RNN, CNN, Transformer)\n",
    "- 부정 코멘트 구분: NLP\n",
    "- 긴 문서 요약: NLP\n",
    "- 챗봇/개인비서: NLU, Q&A module 등의 NLP컴포넌트\n",
    "- 성능지표를 활용하여 내년 수익 예측: 회귀(선형 회귀, 다항 회귀, 회귀SVM, 회귀 랜덤 포레스트, 인공신경망, CNN, RNN, Transformer)\n",
    "- 음성 명령에 반응하는 앱: 음성 인식-길고 복잡한 시퀀스(CNN, RNN, transformer)\n",
    "- 신용카드 부정거래 감지: 이상치 탐지 작업\n",
    "- 구매 이력 기반 마케팅 전략 계획: 군집 작업\n",
    "- 고차원의 복잡한 데이터셋을 그래프로 표현: 데이터 시각화, 차원 축소 기법 활용\n",
    "- 과거 구매 이력 기반 관심 상품 추천: 추천 시스템(인공 신경망을 이용)\n",
    "- 지능형 게임 봇: 강화학습\n",
    "\n",
    "# 머신러닝 시스템의 종류\n",
    "## 지도 학습과 비지도 학습\n",
    "- **학습하는 동안의 감독 형태나 정보량**\n",
    "- 지도 학습\n",
    "  - 알고리즘에 주입하는 훈련데이터(with 레이블=답)\n",
    "  - 분류(ex.스팸 필터)\n",
    "  - 회귀: 예측 변수라 부르는 feature을 사용해 target 수치를 예측\n",
    "    - 분류 알고리즘을 회귀에 사용: 로지스틱 회귀\n",
    "  > attribute vs feature: 데이터 타입 vs 데이터타입+값\n",
    "  - 알고리즘: k-최근접 이웃, 선형 회귀, 로지스틱 회귀, 서포트 벡터 머신, 결정 트리와 랜덤 포레스트, 신경망\n",
    "- 비지도 학습\n",
    "  - 훈련 데이터에 레이블이 없는 상태에서 학습\n",
    "  - 알고리즘:\n",
    "    - 군집: 비슷한 데이터를 그룹으로 묶음.\n",
    "      - k-평균 \n",
    "      - DBSCAN\n",
    "      - 계층 군집 분석-HCA\n",
    "    - 이상치 탐지와 특이치 탐지: 정상 샘플을 입력받아 이를 인식하도록 훈련 후 새로운 샘플을 보고 정상 데이터인지 이상치인지 판단하는 이상치 탐지, 훈련 세트에 있는 모든 샘플과 달라보이는 새로운 샘플을 탐지하는 특이치 탐지\n",
    "      - one-class SVM\n",
    "      - isolation forest\n",
    "    - 시각화와 차원 축소: 레이블이 없는 대규모의 고차원 데이터를 도식화 시켜주는 시각화, 많은 정보를 잃지 않으면서 데이터를 간소화하는 차원 축소(상관관계가 있는 여러 특성을 하나로 합침-특성 추출)\n",
    "      - 주성분 분석-PCA\n",
    "      - 커널 PCA\n",
    "      - 지역적 선형 임베딩-LLE\n",
    "      - t-SNE\n",
    "    - 연관 규칙 학습: 대량의 데이터에서 특성 간 흥미로운 관계를 찾는 것\n",
    "      - Apriori, \n",
    "      - Eclat\n",
    "- 준지도 학습\n",
    "  - 일부만 레이블이 있는 데이터를 다루는 알고리즘\n",
    "  - 심층 신뢰 신경망(DBN)은 비지도 학습인 제한된 볼츠만 머신(RBM)를 여러 겹으로 쌓은 것\n",
    "- 강화 학습\n",
    "  - 학습하는 시스템(에이전트)가 환경을 관찰해서 행동을 실행하고 그 결과로 보상/패널티를 받으며 정책이라고 부르는 최상의 전략을 스스로 학습\n",
    "## 배치 학습과 온라인 학습\n",
    "- **입력 데이터의 스트림으로부터 점진적으로 학습할 수 있는지 여부**\n",
    "- 배치 학습: 점진적 학습X. \n",
    "  - 가용한 데이터를 모두 사용해 훈련->시간과 자원을 많이 소모->오프라인 학습\n",
    "  - 새로운 데이터에 대해 학습하려면 새로운 버전을 처음부터 다시 훈련해야함, 그 후 교체\n",
    "  - 자원이 제한된 시스템에서는 문제가 많음\n",
    "- 온라인 학습: 점진적 학습O.\n",
    "  - 데이터를 순차적으로 한 개씩 또는 미니 배치라 부르는 작은 묶음 단위로 주입하여 시스템을 훈련->매 학습 단계에서 시간과 비용을 절약 가능->즉시 학습 가능\n",
    "  - 빠른 변화에 스스로 적응해야하는 시스템, 컴퓨팅 자원이 제한된 시스템에서 사용.\n",
    "  - 외부 메모리 학습: 컴퓨터 한 대의 메인 메모리에 들어갈 수 없는 큰 데이터셋을 학습하는 시스템에 온라인 학습 알고리즘을 적용하는 경우\n",
    "  - 학습률: 중요한 파라미터(변화하는 데이터에 얼마나 빠르게 적응할 것인지)\n",
    "  - 시스템에 나쁜 데이터가 주입되었을 때 성능이 점진적으로 감소->모니터링과 성능 감소 시 즉각 학습 중단\n",
    "## 사례 기반 학습과 모델 기반 학습\n",
    "- 어떻게 일반화(훈련데이터로 학습하고 훈련 데이터에서 예측을 만드는 것) 되는가.\n",
    "- 사례 기반 학습: 시스템이 훈련 샘플을 기억함으로써 학습하고 **유사도 측정**을 사용해 새로운 데이터와 학습된 샘플을 비교하는 식으로 일반화.\n",
    "- 모델 기반 학습: 샘플들의 모델을 만들어 예측에 사용\n",
    "  - 흩어진 데이터에서 경향을 찾아(데이터 분석) -> 모델링(모델 선택) -> 모델 파라미터를 조정하여(모델이 얼마나 좋은지를 측정하는 **효용 함수**를 정의하거나 나쁜지를 측정하는 **비용 함수**를 정의하고 훈련시킴) -> 새로운 데이터에 모델을 적용해 예측(추론)\n",
    "\n",
    "# 머신러닝의 주요 도전 과제\n",
    "## 충분하지 않은 양의 훈련 데이터\n",
    "- 아주 간단한 문제에서조차 수천 개의 데이터가 필요, 이미지나 음성 인식 같은 복잡한 문제의 경우 수백만 개가 필요(알고리즘 개발 vs 말뭉치 개발 의 트레이드 오프에 대해 다시 생각할 필요를 제시한 논문 등)\n",
    "## 대표성 없는 훈련 데이터\n",
    "- 일반화하기 원하는 새로운 사례를 훈련 데이터가 잘 대표하는 것이 중요\n",
    "- 샘플이 작을 때 우연에 의한 대표성 없는 데이터=**샘플링 잡음**\n",
    "- **샘플링 편향**: 큰 샘플도 추출 방법이 잘못되면 대표성을 띄지 못함.\n",
    "## 낮은 품질의 데이터\n",
    "- 훈련데이터의 에러, 이상치, 잡음 -> 정제가 필요\n",
    "  - 일부 샘플이 이상치일 경우->무시/수동으로 고치기\n",
    "  - 일부 샘플에 특성 몇 개가 빠져있을 경우->특성을 무시할지, 샘플을 무시할지, 빠진 값을 채울지, 특성을 넣은 모델과 제외한 모델을 따로 훈련시킬지\n",
    "## 관련 없는 특성\n",
    "- 특성 공학(feature engineering)\n",
    "  - 특성 선택: 가지고 있는 특성 중 훈련에 가장 유용한 특성을 선택\n",
    "  - 특성 추출: 특성을 결합하여 더 유용한 특성을 만듦(차원 축소 알고리즘 등)\n",
    "  - 새로운 데이터를 수집해 새 특성을 만듦\n",
    "## 훈련 데이터 과대적합\n",
    "- 과대적합: 과도한 일반화, 모델이 훈련 데이터에 너무 잘 맞지만 일반성이 떨어짐.\n",
    "  - 과대적합은 훈련 데이터에 있는 잡음의 양에 비해 모델이 너무 복잡할 때 잠음 섞인 패턴을 감지하며 발생\n",
    "    - 단순화: 파라미터 수가 적은 모델을 선택/훈련 데이터에 있는 특성 수 줄이기/모델에 제약\n",
    "    - 훈련 데이터의 양을 늘리기\n",
    "    - 훈련 데이터의 잡음 줄이기(오류 데이터 수정, 이상치 제거)\n",
    "- 규제: 과대적합의 위험을 감소시키기 위해 모델에 제약을 가하는 것(모델 파라미터의 개수 등이 자유도degree of freedom를 결정)\n",
    "  - 적용할 규제의 양은 하이퍼파라미터가 결정(!=모델의 파라미터; ==학습 알고리즘의 파라미터)\n",
    "## 훈련 데이터 과소적합\n",
    "- 과소적합: 모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못할 때 발생\n",
    "- 해결법: 모델 파라미터가 더 많은 강력한 모델을 선택, 학습 알고리즘에 더 좋은 특성을 제공, 모델의 제약을 줄이기\n",
    "\n",
    "# 테스트와 검증\n",
    "- 모델을 새로운 샘플에 실제로 적용->훈련 데이터를 훈련set과 테스트set으로 나눠 훈련 및 테스트\n",
    "- 새로운 샘플에 대한 오류 비율=일반화 오차(외부 샘플 오차), 테스트set에서 모델을 평가함으로써 오차에 대한 추정값을 얻음\n",
    "## 하이퍼파라미터 튜닝과 모델 선택\n",
    "- 모델을 선택할때, 훈련set로 훈련 후 테스트set을 이용해 비교\n",
    "- 선택 후 규제 적용 시 하이퍼파라미터 값을 선택->여러 하이퍼파라미터에 따른 훈련을 반복하기->테스트세트에 최적화된 모델을 피하기 위해 **홀드아웃 검증**을 사용\n",
    "  - 훈련 세트의 일부를 떼어내어(검증 세트, 개발 세트, 데브 세트) 여러 후보를 평가 후 가장 좋은 하나를 선택하여 여러 모델을 훈련 후 선택->(검증 세트를 포함한) 전체 훈련 세트에서 다시 훈련하여 최종 모델을 만듦.\n",
    "  - 검증 세트의 크기 문제 -> 교차검증(작은 검증 세트를 여러 개 사용해 반복적으로 수행)\n",
    "- 데이터 불일치: 많은 양의 훈련 데이터를 얻을 수 있지만 중요한 건 검증 세트와 테스트 세트가 실전에서 기대하는 데이터를 잘 대표해야함. **훈련-개발 세트**(훈련 세트의 일부를 떼어내어 다른 세트를 만드는 것)\n",
    "- No Free Lunch 이론: 어떤 데이터를 버리고 남길지 정하기 위해(모델은 간소화과정이기 때문) 하는 가정"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
